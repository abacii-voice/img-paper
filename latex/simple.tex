\title{A Very Simple \LaTeXe{} Template}
\author{
	Nicholas Piano \\
	Department of Engineering\\
	Cambridge University\\
}
\date{\today}

\documentclass[12pt]{article}

\begin{document}
\maketitle

\begin{abstract}
Accurate cell segmentation is crucial to biological and medical studies in providing representative data of cell movements and shapes to judge the effects of drugs and other environmental changes. Current methods rely on outlining the cell projected in 2D or a volumetric approximation based on 3D data. A common imaging method is confocal microscopy, where the images stored capture a range of focal planes in an environment. This provides 3D data and the ability to move an object of interest in and out of focus after the images have been captured, potentially offering accurate segmentation. However, conventional segmentation software fails to fully exploit the 3D nature of the data and is unable to make complex associations between image channels.

Here we describe a method for selecting regions of the brightfield channel that contain clear edges suitable for segmentation by determining the XYZ coordinates of bright regions in the GFP. This exploits the relationship between the coordinate systems of the image sets, since the majority of the 3D set of brightfield images is blurred and unsuitable for segmentation. Images of the environment can thus be simplified into a 2D projection that can be readily processed by CellProfiler or ImageJ. This method has been tested on breast cancer cells in a PDMS micro-fluidics environment and yields clear segmentation. This is an improvement over previous 2D methods of image pre-processing, which are unable to extract usable information from the 3D environment.
\end{abstract}

\section{Introduction}
1. Describe problem in field, and an idea of the solution. \\

Accurate measurement of cell morphodynamics is an essential part of live-cell studies. Cell shape can be measured by distinguishing dark edges and bright cell interiors and differentiating them from the background of the image in a process called segmentation. Newly developed microfluidics techniques allow in vitro studies of complex 3D environments. In order to study live cells moving in this environment, 3D imaging is done using a confocal microscope. Cell segmentation is then done using image recognition software such as CellProfiler or ImageJ. Ideally, the cell shape should be captured and analysed in 3D, but imaging limitations can prevent an adequate 3D reconstruction. These limitations include cell overheating from excessive contact with the laser used to produce a fluorescent response, lower resolution from a larger field of view that allows more cells to be imaged, and the necessary time delay between frames to allow the entire field to be imaged. These factors contribute to lower image quality, which prevents the extraction of high-quality shape data from the images. A possible solution is to use the relatively high-quality brightfield images to determine the shape of the cell. \\

2. Describe a previous study or studies done to try to solve this problem. \\

In their 2009 paper, Selinummi et al. attempt to solve this problem by scanning the brightfield in 3D. Although brightfield data does not contain 3D information, intensity at a location will vary as an object moves into and out of focus by moving the current Z plane. This variation can indicate the presence of an object, and can be quantified mathematically to produce a highlighted image showing areas likely to contain objects. This works to a degree in a simple environment, but fails in more complex scenarios. It is unable to determine the Z location of individual objects, differentiate between objects such as different cell types and PMDS (a plastic compound used as a structural material), or accurately represent the boundary of a cell due to distortion. \\

3. Describe the goal of the current study. \\

In this study, we used 3D information from a fluorescent GFP (Green Fluorescent Protein) channel to allow the segmentation of brightfield images by finding levels with clear edges. This exploits the relationship between the coordinate systems of the image sets. Conventional cell segmentation software such as CellProfiler fails when presented with a 3D set of brightfield data. The method presented in this study pre-processes the 3D image data to allow segmentation via conventional means. Since the coordinate systems of the brightfield and GFP images represent the same space, high intensity GFP at a single level, Z, and at a fixed location, XY, can indicate the presence of clear, dark edges of an object in the brightfield. For every point, XY, in the image, the corresponding Z level of high intensity GFP can be determined. This can then be used to combine all the high-quality edges into a single 2D image, which is then ready for conventional 2D segmentation.

\section{Method}
Give all details of the microscope setup including makes of equipment.

1. Make of microscope, serial number \\
2. Pinhole size, aperture, other camera properties \\
3. Type of cancer cells, size, speed, etc. \\
4. Contrast, histograms, laser intensity \\
5. GFP type, staining method, timescales. \\
6. Timing of job imaging \\

1. Coordinate systems \\

Images were grouped according to frame and channel. Images of the same frame and the same channel could be organised into a 3D block of pixels with X, Y and Z coordinates. 3D smoothing and noise-reduction could then be applied to this structure. Each column of pixels, or a single line of pixels with a fixed XY coordinate and the full range of Z coordinates, could be used to build up an intensity distribution in Z. This is known in this study as a ``profile". The GFP channel provides 3D data since levels can be optically separated from each other [[[ref]]]. High intensity at a certain Z level indicates the presence of an object at that location in the original environment. Typically, the profile will have a low value when passing through the background, and a high value when passing through an object. This leads to a peak near the centre of an object. The location of the peak in Z and other properties of the distribution can allow pixels from the brightfield that show clear edges to be selected and compiled into a useful image. \\

2. The GFP profile \\

Figure [[[fig]]] shows an example of a profile for a single pixel. The profile can be generated using two parameters; namely, the amount of gaussian smoothing applied to the image to reduce noise, [[[sigma]]], and the radius of the column in XY around the position of the profile, [[[r]]]. Both of these parameters can be adjusted to affect the output. A discussion of their optimum ranges in given in Section [[[section]]]. They both define forms of smoothing. [[[sigma]]] is the radius of the 3D gaussian kernel. [[[r]]] is the radius of a linear smoothing filter in XY. The distribution is then generated using the algorithm shown in Equation [[[eq]]]. The purpose of such a profile is not to locate objects. The assumption is that high resolution GFP indicates the presence of marked cell tissue. The value [[[sigma]]] was chosen to lie between 3-5 pixels to reduce noise while not completely breaking down fine image features approximately 2-3 pixels in size. A value of between 2-3 pixels was chosen for [[[r]]] to ensure that neighbouring pixels had a smooth transition between their Z levels. This would make continuous objects such as cells that are likely to lie around a single Z level easier to recognise as a whole. \\

3. [[[zMod]]] and [[[zBF]]] \\

Once the profile has been generated, several properties can be used to aide segmentation. Firstly, the Z position of the maximum value in the distribution represents the centre of the object containing GFP, at least at the location of that particular column. Secondly, the variance of the distribution can show how bright the GFP becomes with respect to the surrounding background. This is often more useful than absolute intensity since its value is based on the presence of a relatively large peak. This can better highlight parts of the cell whose brightness might be lower than average, but still contain an intensity peak. The values can be obtained in a parallel manner as follows: \\

[[[parallelisation using numpy]]] \\

If the algorithm is applied to each XY location in the image, new images can be created using the values of interest such as the Z location and the variance. The image generated using the value of the Z location for each pixel is known here as [[[zMod]]]. It is a height map across the 3D environment. It does not contain enough information for segmentation, but it can be combined with the brightfield data to yield a new image, [[[zBF]]]. The brightfield does not contain intrinsic 3D data, but the sharpness of features in the image is best around a single Z location. This is the location of the object, and consequently, the location specified by [[[zMod]]]. Hence, each value in [[[zMod]]] can be used to select a brightfield value from the 3D stack of brightfield images and place it into the corresponding location in [[[zBF]]]. The result is a single 2D brightfield image containing features from all parts of the environment that are sharp and in-focus, regardless of their original Z location. \\

\section{Results}
1. List of steps \\

A graphical layout of the steps taken to modify the images is shown in Figure [[[fig]]]. First, the images are organised by frame and channel. Each frame is loaded as a set of 3D stacks, one for each channel. In this case, only the GFP and the brightfield were used. The GFP is smoothed to reduce noise. A new image, [[[zMod]]], stores the Z position of the point of maximum intensity for each profile. This is analogous to a terrain showing the height of each point in the environment. A new brightfield image, [[[zBF]]], is then created by selecting brightfield pixel values from the 3D stack whose Z position is indicated by the value stored in [[[zMod]]] at the same XY position. In this manner, brightfield pixels are selected only from the brightest regions of the GFP coordinate system, where the objects containing GFP are in-focus and have clear, visible edges suitable for segmentation. The [[[zBF]]] image can then be segmented using conventional 2D segmentation. \\

2. Further improvements to segmentation using 3D data \\

2D segmentation algorithms are unable to take account of 3D information that could inform more accurate segmentation of an object. For example, GFP intensity information can be used to highlight areas of an image that contain cells to prevent the segmentation from extending into the background. \\

\section{Discussion}


\section{Conclusions}


\end{document}
